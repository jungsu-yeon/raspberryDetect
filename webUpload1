import cv2
import RPi.GPIO as GPIO
import time
import math
import numpy as np
import numpy.ma as ma
from flask import Flask, send_file, render_template
from datetime import datetime
import os
import threading

BUZZER_PIN = 18
app = Flask(__name__)

GPIO.setmode(GPIO.BCM)
GPIO.setup(BUZZER_PIN, GPIO.OUT)

cascade_xml = '/home/pi/rpi_edu-master/03multimedia/haarcascade_frontalface_default.xml'
cascade = cv2.CascadeClassifier(cascade_xml)

cam = cv2.VideoCapture(-1)
cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

new_face_arr = np.zeros((4, 2))
old_face_arr = np.zeros((4, 2))
all_dist_arr = np.zeros((4, 4))

tracking_threshold = 50

old_face_count = 0
diff_face_count = 0
no_detect_count = 0

now = datetime.now()
today = now.strftime('%Y-%m-%d')
current_time = now.strftime('%H-%M-%S')
display_width = 800
display_height = 480

def make_filename():
    visitor_folder = os.path.join('static','visitor', today)
    if not os.path.exists(visitor_folder):
        os.makedirs(visitor_folder)
    filename = os.path.join(visitor_folder, f"{current_time}.jpg")
    return filename

def buzzer_on():
    GPIO.output(BUZZER_PIN, GPIO.HIGH)
    time.sleep(0.5)
    GPIO.output(BUZZER_PIN, GPIO.LOW)

def calc_dist(img, faces):  
    global send_filename
    send_filename = make_filename()  # send_filename 업데이트
    new_face_arr.fill(0)
    if len(faces) > 4:
        faces = faces[:4]
    else:
        for idx, (x, y, w, h) in enumerate(faces):
            center_x = x + w // 2
            center_y = y + h // 2
            new_face_arr[idx][0] = center_x
            new_face_arr[idx][1] = center_y
            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)
            cv2.putText(img, f'{idx} : ({x+w//2}, {y+h//2})', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)
            print("new_face_arr = \n{}\n".format(new_face_arr))
            cv2.imwrite(send_filename, img)  # 이미지 저장
    for i in range(4):
        for j in range(4):
            all_dist_arr[i][j] = round(math.sqrt((new_face_arr[i][0]-old_face_arr[j][0])**2+(new_face_arr[i][1]-old_face_arr[j][1])**2), 1)
    print("all_dist_arr = \n{}\n".format(all_dist_arr))

def new_arr_sort():
    min_index = 0
    for i, row in enumerate(all_dist_arr):
        min_index = np.argmin(row)
        if all_dist_arr[i][min_index] < tracking_threshold:
            old_face_arr[min_index] = new_face_arr[i]
        else:
            old_face_arr[min_index] = 0

def capture_frames():
    global no_detect_count
    global old_face_arr
    global diff_face_count
    global old_face_count
    global send_filename  # send_filename 전역 변수로 설정
    
    while True:
        ret, img = cam.read()
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=3, minSize=(10, 10))
        current_face_count = len(faces)
        if current_face_count == 0:
            no_detect_count += 1
            if no_detect_count > 30:
                no_detect_count = 0
                old_face_count = 0
                old_face_arr.fill(0)
                new_face_arr.fill(0)
                all_dist_arr.fill(0)
        else:
            print(f'faces={len(faces)}')
            no_detect_count = 0
            print("old_face_arr = \n{}\n".format(old_face_arr))
            if current_face_count == old_face_count:
                calc_dist(img, faces)  
                new_arr_sort()
                old_face_count = current_face_count
            else:
                diff_face_count += 1
                if diff_face_count > 5:
                    calc_dist(img, faces)  
                    diff_face_count = 0
                    if old_face_count == 0:
                        old_face_arr = new_face_arr.copy()
                    else:
                        new_arr_sort()
                    if current_face_count > old_face_count:
                        buzzer_on()
                    old_face_count = current_face_count
                print("old_face_count = \n{}\n".format(old_face_count))
        cv2.namedWindow('Face Detection', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('Face Detection', display_width, display_height)
        cv2.imshow('Face Detection', img)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    GPIO.cleanup()
    cam.release()
    cv2.destroyAllWindows()

@app.route('/')
def main():
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    global send_filename
    
    if send_filename:
        return send_file(send_filename, mimetype='image/jpg')
    else:
        return 'No Visitor'

if __name__ == '__main__':
    t1 = threading.Thread(target=capture_frames)
    t1.start()
    app.run(host='0.0.0.0', port=6060, debug=True)
