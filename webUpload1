import cv2
import RPi.GPIO as GPIO
import time
import math
import numpy as np
from flask import Flask, Response, render_template

BUZZER_PIN = 18

GPIO.setmode(GPIO.BCM)
GPIO.setup(BUZZER_PIN, GPIO.OUT)

cascade_xml = '/home/pi/rpi_edu-master/03multimedia/haarcascade_frontalface_default.xml'
cascade = cv2.CascadeClassifier(cascade_xml)

cam = cv2.VideoCapture(-1)
cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

new_face_arr = np.zeros((4, 2))
old_face_arr = np.zeros((4, 2))
all_dist_arr = np.zeros((4, 4))

tracking_threshold = 50

old_face_count = 0
diff_face_count = 0
no_detect_count = 0

display_width = 800
display_height = 480

app = Flask(__name__)
GPIO.setwarnings(False)


def buzzer_on():
    GPIO.output(BUZZER_PIN, GPIO.HIGH)
    time.sleep(0.5)
    GPIO.output(BUZZER_PIN, GPIO.LOW)


def detect_faces():
    while True:
        ret, img = cam.read()
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=3, minSize=(10, 10))
        current_face_count = len(faces)

        if current_face_count == 0:
            no_detect_count += 1
            if no_detect_count > 30:
                no_detect_count = 0
                old_face_count = 0
                old_face_arr.fill(0)
                new_face_arr.fill(0)
                all_dist_arr.fill(0)
        else:
            print(f'faces={len(faces)}')
            no_detect_count = 0
            if current_face_count == old_face_count:
                calc_dist(faces)
                new_arr_sort()
                old_face_count = current_face_count
            else:
                diff_face_count += 1
                if diff_face_count > 5:
                    calc_dist(faces)
                    diff_face_count = 0
                    if old_face_count == 0:
                        old_face_arr = new_face_arr.copy()
                    else:
                        new_arr_sort()

                    if current_face_count > old_face_count:
                        buzzer_on()
                    old_face_count = current_face_count

        ret, buffer = cv2.imencode('.jpg', img)
        frame = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')


def calc_dist(faces):
    new_face_arr.fill(0)
    if len(faces) > 4:
        faces = faces[:4]
    else:
        for idx, (x, y, w, h) in enumerate(faces):
            center_x = x + w // 2
            center_y = y + h // 2

            new_face_arr[idx][0] = center_x
            new_face_arr[idx][1] = center_y

            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)
            cv2.putText(img, f'{idx} : ({x + w // 2}, {y + h // 2})', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9,
                        (0, 0, 255), 2)

    for i in range(4):
        for j in range(4):
            all_dist_arr[i][j] = round(math.sqrt((new_face_arr[i][0] - old_face_arr[j][0]) ** 2 +
                                                  (new_face_arr[i][1] - old_face_arr[j][1]) ** 2), 1)
    print("all_dist_arr = \n{}\n".format(all_dist_arr))


def new_arr_sort():
    min_index = 0
    for i, row in enumerate(all_dist_arr):
        min_index = np.argmin(row)

        if all_dist_arr[i][min_index] < tracking_threshold:
            old_face_arr[min_index] = new_face_arr[i]
        else:
            old_face_arr[min_index] = 0


@app.route('/')
def index():
    return render_template('index.html')


@app.route('/video_feed')
def video_feed():
    return Response(detect_faces(), mimetype='multipart/x-mixed-replace; boundary=frame')


if __name__ == "__main__":
    app.run(debug=True, host='0.0.0.0')

///////////////////////////////
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection</title>
</head>
<body>
    <h1>Face Detection</h1>
    <img src="{{ url_for('video_feed') }}" width="800" height="480">
</body>
</html>
